{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json files\n",
    "\n",
    "with open(\"./data/raw_data/all_sessions.json\", \"r\") as source:\n",
    "    sessions = json.load(source)\n",
    "\n",
    "with open(\"./data/raw_data/user_ids_and_session_ids.json\", \"r\") as source:\n",
    "    users = json.load(source)\n",
    "\n",
    "with open(\"./data/raw_data/trackidsandstringtags.json\", \"r\") as source:\n",
    "    tracks = json.load(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load already processed dataframes\n",
    "\n",
    "with open(\"./data/sessions_10sessions_2plays_tf.json\", \"r\") as source:\n",
    "    sessions_df = pd.read_json(source, orient=\"index\")\n",
    "\n",
    "with open(\"./data/users_10sessions_2plays_tf.json\", \"r\") as source:\n",
    "    users_df = pd.read_json(source, orient=\"index\")\n",
    "\n",
    "with open(\"./data/tracks_10sessions_2plays_tf.json\", \"r\") as source:\n",
    "    track_df = pd.read_json(source, orient=\"index\")\n",
    "\n",
    "with open(\"./data/tags_10sessions_2plays_tf.json\", \"r\") as source:\n",
    "    tags_df = pd.read_json(source, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes\n",
    "\n",
    "users_df = pd.DataFrame([[int(key), value] for (key, value) in users.items()], columns=[\"user_id\", \"sessions\"])\n",
    "users_df.set_index(\"user_id\", inplace=True)\n",
    "sessions_df = pd.DataFrame([[int(key), value] for (key, value) in sessions.items()], columns=[\"session_id\", \"session\"])\n",
    "sessions_df.set_index(\"session_id\", inplace=True)\n",
    "track_df = pd.DataFrame([[int(key), value] for (key, value) in tracks.items()], columns=[\"track_id\", \"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all sessions with less than 5 songs or invalid songs\n",
    "\n",
    "sessions_df = sessions_df[sessions_df[\"session\"].apply(lambda l: len(l) >= 5) == True]\n",
    "sessions_df = sessions_df[sessions_df[\"session\"].apply(lambda l: any(None in sl for sl in l)) == False]\n",
    "sessions_df = sessions_df[sessions_df[\"session\"].apply(lambda l: any(sl[3] == 1 for sl in l)) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all sessions that starts with a track with no tags (tensorflow compatibility)\n",
    "\n",
    "track_id_to_tags_dict = dict(zip(track_df.track_id.values.tolist(), track_df.tags.values.tolist()))\n",
    "\n",
    "def find_first_track_no_tags(session):\n",
    "    tags = track_id_to_tags_dict[int(session[0][0])]\n",
    "    if not any(tags):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "sessions_df = sessions_df[sessions_df[\"session\"].apply(find_first_track_no_tags) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get playcount for each track across all sessions\n",
    "\n",
    "track_ids = track_df.track_id.values.tolist()\n",
    "track_plays = [int(track[0]) for session in sessions_df.session.values.tolist() for track in session]\n",
    "initial_plays = [0] * len(track_ids)\n",
    "track_plays_dict = dict(zip(track_ids, initial_plays))\n",
    "\n",
    "for tid in track_plays:\n",
    "    track_plays_dict[tid] += 1\n",
    "\n",
    "track_df[\"plays\"] = track_df[\"track_id\"].apply(lambda tid: track_plays_dict[tid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tracks with more than one play\n",
    "\n",
    "track_df = track_df[track_df[\"plays\"] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build valid tracks dict\n",
    "\n",
    "valid_ids = track_df.track_id.values.tolist()\n",
    "idxs = [i for i in range(max(valid_ids) + 1)]\n",
    "valid_dict = dict(zip(idxs, [False] * len(idxs)))\n",
    "\n",
    "for tid in valid_ids:\n",
    "    valid_dict[tid] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove sessions with single play songs\n",
    "\n",
    "def contains_invalid(session):\n",
    "    for track in session:\n",
    "        if valid_dict[int(track[0])] == False:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "sessions_df = sessions_df[sessions_df[\"session\"].apply(contains_invalid) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove invalid sessions from users\n",
    "\n",
    "session_ids = sessions_df.index.values\n",
    "\n",
    "def remove_invalid_sessions(sessions):\n",
    "    exists = []\n",
    "    for session_id in sessions:\n",
    "        if session_id in session_ids:\n",
    "            exists.append(session_id)\n",
    "    return exists\n",
    "\n",
    "users_df[\"clean_sessions\"] = users_df[\"sessions\"].apply(lambda l: remove_invalid_sessions(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove users with no sessions\n",
    "\n",
    "users_df.drop(users_df[users_df[\"clean_sessions\"].apply(lambda l: len(l)) == 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# create subset of user sessions\n",
    "\n",
    "def get_six_month_history(sessions):\n",
    "    if len(sessions) == 1:\n",
    "        return sessions\n",
    "    start_ts = pd.to_datetime(sessions_df.loc[sessions[0]][\"session\"][0][1])\n",
    "    for i in range(1, len(sessions)):\n",
    "        current_ts = pd.to_datetime(sessions_df.loc[sessions[i]][\"session\"][0][1])\n",
    "        if (current_ts - start_ts) > timedelta(days=183):\n",
    "            return sessions[:i]\n",
    "    return sessions\n",
    "\n",
    "users_df[\"sessions_subset\"] = users_df[\"clean_sessions\"].apply(get_six_month_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get session count for users\n",
    "\n",
    "users_df[\"session_count\"] = users_df[\"sessions_subset\"].apply(lambda l: len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove users with less than 10 sessions\n",
    "\n",
    "users_df = users_df[users_df[\"session_count\"] >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample users to create smaller dataset\n",
    "\n",
    "users_df = users_df.sample(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# remove sessions not in user sessions subset\n",
    "\n",
    "subset_sessions = [item for sublist in users_df.sessions_subset.values.tolist() for item in sublist]\n",
    "subset_sessions_df = sessions_df.drop(sessions_df.loc[~sessions_df.index.isin(subset_sessions)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove songs not in any subset sessions\n",
    "\n",
    "valid_songs = list(set([int(track[0]) for session in subset_sessions_df.session.values.tolist() for track in session]))\n",
    "valid_songs.sort()\n",
    "subset_track_df = track_df.drop(track_df[~track_df[\"track_id\"].isin(valid_songs)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort track df by ids and create a new index column\n",
    "\n",
    "subset_track_df = subset_track_df.sort_values(\"track_id\").reset_index().drop(\"index\", axis=1)\n",
    "subset_track_df.index = subset_track_df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tag dictionary and get tag ids\n",
    "\n",
    "total_tags = [item for sublist in subset_track_df.tags.values.tolist() for item in sublist]\n",
    "unique_tags = list(set(total_tags))\n",
    "\n",
    "tags_dict = {}\n",
    "for index, tag in enumerate(unique_tags):\n",
    "    tags_dict[tag] = index + 1\n",
    "\n",
    "def get_tag_ids(tags):\n",
    "    ids = []\n",
    "    for tag in tags:\n",
    "        ids.append(tags_dict[tag])\n",
    "    return ids\n",
    "\n",
    "subset_track_df[\"tags\"] = subset_track_df[\"tags\"].apply(get_tag_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tag dataframe\n",
    "\n",
    "tags_df = pd.DataFrame([[key, int(value)] for (key, value) in tags_dict.items()], columns=[\"tag\", \"tag_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_idxs = subset_track_df.index.values.tolist()\n",
    "track_ids = subset_track_df.track_id.values.tolist()\n",
    "\n",
    "track_idxs_dict = dict(zip(track_ids, track_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_tags = subset_track_df.tags.values.tolist()\n",
    "\n",
    "track_tags_dict = dict(zip(track_idxs, track_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get track idxs from ids\n",
    "\n",
    "def get_idxs(session):\n",
    "    session_ids = [int(track[0]) for track in session]\n",
    "    session_idxs = [track_idxs_dict[sid] for sid in session_ids]\n",
    "    return session_idxs\n",
    "\n",
    "subset_sessions_df[\"track_idxs\"] = subset_sessions_df.session.apply(get_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tag idxs from ids\n",
    "\n",
    "def get_tag_idxs(track_idxs):\n",
    "    tags_idxs = []\n",
    "    for idx in track_idxs:\n",
    "        tags_idxs.append(track_tags_dict[idx].copy())\n",
    "    longest_tags = len(max(tags_idxs, key=len)) # find song with most tags\n",
    "    for tags in tags_idxs: # pad tags of other songs with 0\n",
    "        tags.extend([0] * (longest_tags - len(tags)))\n",
    "    return tags_idxs\n",
    "\n",
    "subset_sessions_df[\"tags_idxs\"] = subset_sessions_df.track_idxs.apply(get_tag_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get skip features\n",
    "\n",
    "def get_skip(session):\n",
    "    skips = []\n",
    "    for track in session:\n",
    "        if track[2] < 0.9:\n",
    "            skips.append(2)\n",
    "        else:\n",
    "            skips.append(1)\n",
    "    return skips\n",
    "\n",
    "subset_sessions_df[\"skips\"] = subset_sessions_df[\"session\"].apply(get_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get skip and gap features\n",
    "\n",
    "def get_gap_skip(session):\n",
    "    skips_and_gaps = []\n",
    "    for track in session:\n",
    "        if track[2] < 0.9:\n",
    "            skips_and_gaps.append(2)\n",
    "        elif track[4] >= 30:\n",
    "            skips_and_gaps.append(3)\n",
    "        else:\n",
    "            skips_and_gaps.append(1)\n",
    "    return skips_and_gaps\n",
    "\n",
    "subset_sessions_df[\"action\"] = subset_sessions_df[\"session\"].apply(get_gap_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build session histories\n",
    "\n",
    "user_sessions_list = users_df[\"sessions_subset\"].values.tolist()\n",
    "history_dict = {}\n",
    "\n",
    "for user in user_sessions_list:\n",
    "    for i in range(len(user)):\n",
    "        history_dict[user[i]] = user[:i]\n",
    "\n",
    "subset_sessions_df[\"history\"] = subset_sessions_df.apply(lambda row: history_dict[row.name], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_sessions_df.drop(\"session\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.drop(\"sessions\", axis=1, inplace=True)\n",
    "users_df.drop(\"clean_sessions\", axis=1, inplace=True)\n",
    "users_df.drop(\"session_count\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_sessions_df.drop(\"skips\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "\n",
    "users_df.to_json(\"./data/skips_and_gaps/users_10sessions_2plays_skipsgaps_tf.json\", orient=\"index\")\n",
    "subset_sessions_df.to_json(\"./data/skips_and_gaps/sessions_10sessions_2plays_skipsgaps_tf.json\", orient=\"index\")\n",
    "subset_track_df.to_json(\"./data/skips_and_gaps/tracks_10sessions_2plays_skipsgaps_tf.json\", orient=\"index\")\n",
    "tags_df.to_json(\"./data/skips_and_gaps/tags_10sessions_2plays_skipsgaps_tf.json\", orient=\"index\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bite8c481f3d30e495a84c33c056f825e91",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}