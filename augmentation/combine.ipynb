{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import glob\n",
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# The purpose of this script is to read through all files containing\n",
    "# augmented rows and create two distinct dictionaries: mbid_rows and\n",
    "# normal_rows depending on whether an mbid is available for the song.\n",
    "# There should be 1,505,514 unique tracks and thus augmented rows in \n",
    "# total. We then iterate through all listening events of the 1K data\n",
    "# set and extract sessions. This is done on a user-by-user basis: We\n",
    "# take all events associated with each user and iterate through them.\n",
    "# If 7200 seconds (120 minutes, as per paper) has passed between two \n",
    "# events, we consider them as part of two distinct sessions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last.fm (CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text\n",
    "\n",
    "# Handle all tags.\n",
    "all_tags = {}\n",
    "tag_counter = 1\n",
    "lastfm = {}\n",
    "lastfm_index = 1\n",
    "\n",
    "with open(\"data/lastfm.csv\", \"r\", encoding=\"utf-8\") as source:\n",
    "    reader = csv.reader(source, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    remove = {\"[\": \"\", \"'\": \"\" , \"]\": \"\", '\"': \"\"}\n",
    "    for row in reader:\n",
    "        total_listeners = row[0]\n",
    "        total_playcount = row[1]\n",
    "        duration_lastfm = row[2]\n",
    "        # We clean the tags such that we do not inadvertently include the URL.\n",
    "        # This could be solved by changing the way the lastfm spider writes to \n",
    "        # disk, but as we have not yet done that, these steps are necessary.\n",
    "        tags = replace_all(str(row[3:]).split(\"https://\")[0], remove).split(\", \")\n",
    "        tags = [tag.strip() for tag in tags]\n",
    "        tags = [tag if len(tag) > 0 else None for tag in tags]\n",
    "        tags = list(filter(None, tags))\n",
    "\n",
    "        temp_tags = []\n",
    "        if tags:    \n",
    "            for tag in tags:\n",
    "                if tag not in all_tags:\n",
    "                    all_tags[tag] = tag_counter\n",
    "                    temp_tags.append(tag_counter)\n",
    "                    tag_counter += 1\n",
    "                else:\n",
    "                    temp_tags.append(all_tags[tag])\n",
    "            \n",
    "        track_id = row[-1]\n",
    "        \n",
    "        lastfm[track_id] = {\"track_id\": track_id,\n",
    "                            \"lastfm_index\": lastfm_index,\n",
    "                            \"total_listeners\": total_listeners,\n",
    "                            \"total_playcount\": total_playcount,\n",
    "                            \"duration_lastfm\": duration_lastfm,\n",
    "                            \"tags\": temp_tags}\n",
    "        lastfm_index += 1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"tag_ids.json\", \"w\") as out:\n",
    "    json.dump(all_tags, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle all tags.\n",
    "all_tags = {}\n",
    "tag_counter = 1\n",
    "\n",
    "with open(\"combinedlastfm.json\", \"r\") as source:\n",
    "    lastfm = json.load(source)\n",
    "\n",
    "# Append all unique tracks and assign IDs\n",
    "for _, values in lastfm.items():\n",
    "    track_tags = []\n",
    "    for tag in values[\"tags\"]:\n",
    "        if tag not in all_tags:\n",
    "            all_tags[tag] = tag_counter\n",
    "            track_tags.append(tag_counter)\n",
    "            tag_counter += 1\n",
    "        else:\n",
    "            track_tags.append(all_tags[tag])\n",
    "    \n",
    "    values[\"tags\"] = track_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"release_date\", \"spotify_id\", \"track_id\", \"acousticness\", \n",
    "        \"danceability\", \"energy\", \"instrumentalness\", \"pitch_class\", \n",
    "        \"liveness\", \"loudness\", \"mode\", \"speechiness\", \"tempo\", \n",
    "        \"time_signature\", \"valence\",\"duration_spotify\"]\n",
    "\n",
    "spotify = {}\n",
    "spotify_index = 1\n",
    "with open(\"data/spotify.csv\", \"r\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=\",\")\n",
    "    for row in reader:\n",
    "        content = dict(zip(keys, row))\n",
    "        content[\"spotify_index\"] = spotify_index\n",
    "        spotify[content[\"track_id\"]] = content\n",
    "        spotify_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Tracks\n",
    "\n",
    "We read through the unique-tracks.csv file which has extracted all unique tracks from the listening events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../Downloads/unique-tracks.csv\", \"r\", encoding=\"utf-8\") as csvfile:\n",
    "    raw_tracks = list(csv.reader(csvfile))\n",
    "\n",
    "unique_tracks = {}\n",
    "for index, entry in enumerate(raw_tracks):\n",
    "    track_id = index\n",
    "    track_name = entry[2].strip()\n",
    "    artist_name = entry[0]\n",
    "    key = \"{}{}\".format(artist_name, track_name)\n",
    "    unique_tracks[key] = {\"track_id\": track_id,\n",
    "                          \"track_name\": track_name,\n",
    "                          \"artist_name\": artist_name,\n",
    "                          \"key\": key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Raw\", len(raw_tracks), \"Unique\", len(unique_tracks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listening Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_track_id(artist_name, track_name): \n",
    "    try:\n",
    "        return str(unique_tracks[\"{}{}\".format(artist_name, track_name)][\"track_id\"])\n",
    "    # Some tracks return a KeyError per https://github.com/x775/SW10/issues\n",
    "    except KeyError:\n",
    "        return None\n",
    "        \n",
    "            \n",
    "# Read the listening events of the 1K dataset. This translates\n",
    "# to roughly 19 million events. For each event, we associate it\n",
    "# to a given user as well as locate the track_id of each song. \n",
    "source = \"../../Downloads/lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv\"\n",
    "\n",
    "users = {}\n",
    "ukeys = [\"user_id\", \"timestamp\", \"artist_mbid\", \n",
    "          \"artist_name\", \"mbid_track\", \"track_name\"]\n",
    "with open(source, \"r\", encoding=\"utf-8\") as data:\n",
    "    reader = csv.reader(data, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "    for row in reader:\n",
    "        user_id = int(row[0].split(\"_\")[1])\n",
    "        if user_id in users:\n",
    "            users[user_id].append(dict(zip(ukeys, row)))\n",
    "        else:\n",
    "            users[user_id] = [dict(zip(ukeys, row))]\n",
    "\n",
    "        # In both cases, we add the track_id from our augmented rows.\n",
    "        track_id = find_track_id(users[user_id][-1][\"artist_name\"].strip(),\n",
    "                                 users[user_id][-1][\"track_name\"].strip())\n",
    "        \n",
    "        if track_id:\n",
    "            users[user_id][-1].update({\"track_id\": track_id})\n",
    "        else:\n",
    "            users[user_id][-1].update({\"track_id\": None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"processedusers.json\", \"w\") as out:\n",
    "    json.dump(users, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_average_duration(track_id):\n",
    "     def compute(ld, sd):\n",
    "          if ld and not sd: return int(ld)\n",
    "          if sd and not ld: return int(sd)\n",
    "          if not sd and not ld: return None\n",
    "          return math.ceil((int(ld) + int(sd)) / 2)\n",
    "     \n",
    "     ld = lastfm[track_id][\"duration_lastfm\"]\\\n",
    "          if lastfm[track_id][\"duration_lastfm\"] and len(lastfm[track_id][\"duration_lastfm\"]) > 1\\\n",
    "          else None\n",
    "\n",
    "     sd = None\n",
    "     if track_id in spotify:     \n",
    "          sd = spotify[track_id][\"duration_spotify\"]\\\n",
    "               if spotify[track_id][\"duration_spotify\"] and len(spotify[track_id][\"duration_spotify\"]) > 1\\\n",
    "               else None\n",
    "\n",
    "     return compute(ld, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 7200\n",
    "allowed_fade = 5\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = {}\n",
    "SESSION_ID = 0\n",
    "total = len(users)\n",
    "userssessions = {}\n",
    "for index, user in enumerate(users):\n",
    "    prev_gap = 0\n",
    "    \n",
    "    # Obtain events in chronological order.\n",
    "    user_events_r = list(reversed(users[user]))\n",
    "\n",
    "    # Grab the timestamp from the first event.\n",
    "    prev_timestamp = pd.to_datetime(user_events_r[0][\"timestamp\"])\n",
    "\n",
    "    # Compute the duration of the first track.\n",
    "    try:\n",
    "        average_duration = find_average_duration(str(user_events_r[0][\"track_id\"]))\n",
    "        prev_track_missing = 0\n",
    "    except KeyError:\n",
    "        # If we receive a KeyError when attempting to find the duration, it \n",
    "        # means that the song in question does not exist as outlined here:\n",
    "        # https://github.com/x775/SW10/issues. We thus set missing = 1.\n",
    "        average_duration = 0\n",
    "        prev_track_missing = 1\n",
    "\n",
    "    # If average_duration returns None, we set duration to 0.\n",
    "    prev_track_duration = round(average_duration / 1000) if average_duration else 0\n",
    "\n",
    "    # Prepare the first session of the user. \n",
    "    current_session = [(user_events_r[0][\"track_id\"],\n",
    "                        user_events_r[0][\"timestamp\"])]\n",
    "\n",
    "    user_sessions = []\n",
    "    for event in user_events_r[1:]:\n",
    "        gap = 0\n",
    "        duration = 0\n",
    "\n",
    "        try:\n",
    "            duration = find_average_duration(str(event[\"track_id\"]))\n",
    "            current_track_missing = 0\n",
    "        except KeyError:\n",
    "            current_track_missing = 1\n",
    "            \n",
    "        timestamp = pd.to_datetime(event[\"timestamp\"])\n",
    "\n",
    "        # If the current song has been played after a break of more than the duration \n",
    "        # of the previous song and the specified cutoff (default 7200 seconds / 120 \n",
    "        # minutes), we consider the song part of a new session. \n",
    "        if timestamp > (prev_timestamp \n",
    "                        + datetime.timedelta(seconds=prev_track_duration)\n",
    "                        + datetime.timedelta(seconds=cutoff)):\n",
    "            # We assume that the previous song was completed in full and has no gap.\n",
    "            current_session[-1] = current_session[-1] + (1.0, prev_track_missing, prev_gap)\n",
    "            sessions[SESSION_ID] = current_session\n",
    "            user_sessions.append(SESSION_ID)\n",
    "            # We prepare a new session.\n",
    "            current_session = [(event[\"track_id\"], event[\"timestamp\"])]\n",
    "            SESSION_ID += 1\n",
    "        else:\n",
    "            # Seconds between current and previous track starting.\n",
    "            difference = (timestamp - prev_timestamp).seconds\n",
    "\n",
    "            if prev_track_duration > 0:\n",
    "                if difference >= prev_track_duration:\n",
    "                    abs_seconds = difference - prev_track_duration\n",
    "                    if abs_seconds <= allowed_fade:\n",
    "                        # In case of continuous stream.\n",
    "                        percentage_played = 1.0\n",
    "                    elif abs_seconds >= allowed_fade:\n",
    "                        # In case of a gap (i.e. pause and/or skipped track(s))\n",
    "                        percentage_played = 1.0\n",
    "                        gap = abs_seconds\n",
    "                else:\n",
    "                    # In case of track not played in full.\n",
    "                    percentage_played = round(difference / prev_track_duration, 2)\n",
    "                    if percentage_played > 1:\n",
    "                        percentage_played = 1.0\n",
    "            else:\n",
    "                percentage_played = 1.0\n",
    "                gap = difference\n",
    "            \n",
    "            # Update the percentage_played of the previous entry.\n",
    "            current_session[-1] = current_session[-1] + (percentage_played, prev_track_missing, prev_gap,)\n",
    "            # Append the current entry to the current session.\n",
    "            current_session.append((event[\"track_id\"], event[\"timestamp\"]),)\n",
    "\n",
    "        prev_gap = gap\n",
    "        prev_timestamp = timestamp\n",
    "        prev_track_duration = round(duration / 1000) if duration else 0\n",
    "        prev_track_missing = current_track_missing\n",
    "        \n",
    "    userssessions[index] = user_sessions\n",
    "    print(\"Completed {}/{}\".format(index, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sessions_28march.json\", \"w\") as out:\n",
    "    json.dump(sessions, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songstags = {}\n",
    "for _, value in lastfm.items():\n",
    "    songstags[value[\"track_id\"]] = value[\"tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"track_ids_and_tag_ids.json\", \"w\") as out:\n",
    "    json.dump(songstags, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"user_sessions.json\", \"w\") as out:\n",
    "    json.dump(userssessions, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "complete_sessions = {}\n",
    "with open(\"data/sessions_complete.json\", \"r\") as source:\n",
    "    complete_sessions = json.load(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, session in complete_sessions.items():\n",
    "    for entry in session:\n",
    "        if 770512 in entry:\n",
    "            print(\"found something\")\n",
    "            print(entry)\n",
    "            print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(users.keys())[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}